{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kK3alCdFflQX"
   },
   "source": [
    "### CNN on CIFR Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHCYMwwXflQd"
   },
   "source": [
    "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
    "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
    "3.  You cannot use Dense Layers (also called fully connected layers), or DropOut.\n",
    "4.  You MUST use Image Augmentation Techniques.\n",
    "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
    "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
    "7.  You cannot use test images for training the model.\n",
    "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
    "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
    "10. You cannot have more than 1 Million parameters in total\n",
    "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
    "12. You can use any optimization algorithm you need. \n",
    "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLVcyNYKflQi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "# from keras.datasets import cifar10\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "# from keras.layers import Concatenate\n",
    "# from keras.optimizers import Adam\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bB5RwX0OzYPe"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBxAbUWLCKRK"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "l = 6\n",
    "num_filter = 35\n",
    "compression = 1\n",
    "dropout_rate = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODzpOFXM17li"
   },
   "source": [
    "<h3>Loading Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "DkJYTvGM_hAc",
    "outputId": "65766162-ebf8-41cb-8a65-1f58da20bcfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-wbHmWUzYP3"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PsxDbwS2zYQI",
    "outputId": "0733212c-48ba-4228-e27c-cc68f0c1054b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fm9vRMixzYQY",
    "outputId": "cff97004-cce5-4f89-a72f-6d82e31944e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9s0D0QXF3N-r"
   },
   "source": [
    "<h3>Standardizing Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0w7JjiI23g85"
   },
   "outputs": [],
   "source": [
    "def prep_pixels(train, test):\n",
    "# convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "# normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "# return normalized images\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlZDyP_C3gwn"
   },
   "outputs": [],
   "source": [
    "X_train,X_test=prep_pixels(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "UELbMxuo3mik",
    "outputId": "75b68d43-a794-48f8-9a8d-98a11dbe8ffd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "c=X_train[1]\n",
    "c.shape\n",
    "samples = expand_dims(c, 0)\n",
    "\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "    \n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    \n",
    "    # generate batch of images\n",
    "    batch = it.next()\n",
    "    \n",
    "    # convert to unsigned integers for viewing\n",
    "    image = batch[0].astype('uint8')\n",
    "    \n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(image)\n",
    "\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPNJVwOrCh3A"
   },
   "source": [
    "<h2>Model without using Droupout Layers</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teiaTCnXCf_x"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5dydc6a2Q8k"
   },
   "source": [
    "<h3>Defining the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Agkn8-tzYQ3"
   },
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "YWb0wJfBzYRD",
    "outputId": "a26482a0-1863-4af3-92b8-c73fe5451b5d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/-W6y8xnd--U\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x17700d221d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://arxiv.org/pdf/1608.06993.pdf\n",
    "from IPython.display import IFrame, YouTubeVideo\n",
    "YouTubeVideo(id='-W6y8xnd--U', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Oyox53bbzYRN",
    "outputId": "df283967-87ec-474d-de79-602216443c85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 35)   945         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 35)   140         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 35)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 35)   11025       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 70)   0           conv2d[0][0]                     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 70)   280         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 70)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 35)   22050       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 105)  0           concatenate[0][0]                \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 105)  420         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 105)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 35)   33075       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 140)  0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 140)  560         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 140)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 35)   44100       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 175)  0           concatenate_2[0][0]              \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 175)  700         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 175)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 35)   55125       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 210)  0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 210)  840         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 210)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 35)   66150       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 245)  0           concatenate_4[0][0]              \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 245)  980         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 245)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 35)   8575        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 35)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 35)   140         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 35)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 35)   11025       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 70)   0           average_pooling2d[0][0]          \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 70)   280         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 70)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 35)   22050       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 105)  0           concatenate_6[0][0]              \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 105)  420         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 105)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 35)   33075       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 140)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 140)  560         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 140)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 35)   44100       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 175)  0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 175)  700         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 175)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 35)   55125       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 210)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 210)  840         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 210)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 35)   66150       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 16, 16, 245)  0           concatenate_10[0][0]             \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 245)  980         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 245)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 35)   8575        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 35)     0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 35)     140         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 35)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 35)     11025       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 8, 8, 70)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 70)     280         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 70)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 35)     22050       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 8, 8, 105)    0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 105)    420         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 105)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 35)     33075       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 8, 8, 140)    0           concatenate_13[0][0]             \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 140)    560         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 140)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 35)     44100       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 8, 8, 175)    0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 175)    700         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 175)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 35)     55125       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 8, 8, 210)    0           concatenate_15[0][0]             \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 210)    840         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 210)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 35)     66150       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 8, 8, 245)    0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 245)    980         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 245)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 35)     8575        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 35)     0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 4, 35)     140         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 35)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 4, 35)     11025       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 4, 4, 70)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 4, 70)     280         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 70)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 35)     22050       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 4, 4, 105)    0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 4, 4, 105)    420         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 4, 105)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 4, 4, 35)     33075       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 4, 4, 140)    0           concatenate_19[0][0]             \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 4, 140)    560         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 4, 140)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 35)     44100       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 4, 4, 175)    0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 4, 175)    700         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 175)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 4, 35)     55125       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 4, 4, 210)    0           concatenate_21[0][0]             \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 210)    840         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 210)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 35)     66150       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 4, 4, 245)    0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 245)    980         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 245)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 245)    0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 980)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           9810        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 978,260\n",
      "Trainable params: 970,420\n",
      "Non-trainable params: 7,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zJMk7mI4sSk"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydRen_ov1PYu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"./weights/weights-improve-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6fuPN8g1PYy"
   },
   "source": [
    "<h3>Image Augmentation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXpLeOYt1PYz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(        \n",
    "        rotation_range=30,  # randomly rotate images in the range (deg 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1,  # randomly shift images vertically\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        zoom_range=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ayhN0BF_1PY5"
   },
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "kldloY0kEgAG",
    "outputId": "2bcfe4fb-f2cc-499e-dd48-a4d6e966084f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "390/390 [==============================] - 7186s 18s/step - loss: 1.4390 - accuracy: 0.4752 - val_loss: 1.5504 - val_accuracy: 0.4595\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 5675s 15s/step - loss: 1.0743 - accuracy: 0.6173 - val_loss: 0.9929 - val_accuracy: 0.6529\n",
      "Epoch 3/200\n",
      "390/390 [==============================] - 6809s 17s/step - loss: 0.8897 - accuracy: 0.6829 - val_loss: 1.2890 - val_accuracy: 0.5990\n",
      "Epoch 4/200\n",
      "390/390 [==============================] - 5723s 15s/step - loss: 0.7874 - accuracy: 0.7249 - val_loss: 1.0467 - val_accuracy: 0.6664\n",
      "Epoch 5/200\n",
      "390/390 [==============================] - 5301s 14s/step - loss: 0.7118 - accuracy: 0.7511 - val_loss: 0.8931 - val_accuracy: 0.7154\n",
      "Epoch 6/200\n",
      "390/390 [==============================] - 25164s 65s/step - loss: 0.6576 - accuracy: 0.7699 - val_loss: 0.8908 - val_accuracy: 0.7146\n",
      "Epoch 7/200\n",
      "390/390 [==============================] - 6347s 16s/step - loss: 0.6128 - accuracy: 0.7866 - val_loss: 0.8515 - val_accuracy: 0.7212\n",
      "Epoch 8/200\n",
      "390/390 [==============================] - 6952s 18s/step - loss: 0.5787 - accuracy: 0.7984 - val_loss: 0.8396 - val_accuracy: 0.7407\n",
      "Epoch 9/200\n",
      "390/390 [==============================] - 6522s 17s/step - loss: 0.5389 - accuracy: 0.8136 - val_loss: 0.5389 - val_accuracy: 0.8178\n",
      "Epoch 10/200\n",
      "390/390 [==============================] - 6315s 16s/step - loss: 0.5188 - accuracy: 0.8202 - val_loss: 0.5830 - val_accuracy: 0.8017\n",
      "Epoch 11/200\n",
      "390/390 [==============================] - 6378s 16s/step - loss: 0.4915 - accuracy: 0.8282 - val_loss: 0.8320 - val_accuracy: 0.7516\n",
      "Epoch 12/200\n",
      "390/390 [==============================] - 7733s 20s/step - loss: 0.4687 - accuracy: 0.8358 - val_loss: 0.9455 - val_accuracy: 0.7284\n",
      "Epoch 13/200\n",
      "390/390 [==============================] - 6568s 17s/step - loss: 0.4537 - accuracy: 0.8397 - val_loss: 0.6681 - val_accuracy: 0.7846\n",
      "Epoch 14/200\n",
      "390/390 [==============================] - 6954s 18s/step - loss: 0.4390 - accuracy: 0.8472 - val_loss: 0.7510 - val_accuracy: 0.7653\n",
      "Epoch 15/200\n",
      "390/390 [==============================] - 6645s 17s/step - loss: 0.4147 - accuracy: 0.8556 - val_loss: 0.7358 - val_accuracy: 0.7805\n",
      "Epoch 16/200\n",
      "390/390 [==============================] - 6336s 16s/step - loss: 0.4059 - accuracy: 0.8585 - val_loss: 0.5309 - val_accuracy: 0.8261\n",
      "Epoch 17/200\n",
      "390/390 [==============================] - 21929s 56s/step - loss: 0.3887 - accuracy: 0.8645 - val_loss: 0.6993 - val_accuracy: 0.7905\n",
      "Epoch 18/200\n",
      "390/390 [==============================] - 7054s 18s/step - loss: 0.3777 - accuracy: 0.8672 - val_loss: 0.6070 - val_accuracy: 0.8099\n",
      "Epoch 19/200\n",
      "390/390 [==============================] - 6638s 17s/step - loss: 0.3652 - accuracy: 0.8730 - val_loss: 0.5531 - val_accuracy: 0.8248\n",
      "Epoch 20/200\n",
      "390/390 [==============================] - 7482s 19s/step - loss: 0.3588 - accuracy: 0.8730 - val_loss: 0.6228 - val_accuracy: 0.8086\n",
      "Epoch 21/200\n",
      "390/390 [==============================] - 7021s 18s/step - loss: 0.3436 - accuracy: 0.8803 - val_loss: 0.5267 - val_accuracy: 0.8250\n",
      "Epoch 22/200\n",
      "390/390 [==============================] - 7270s 19s/step - loss: 0.3425 - accuracy: 0.8806 - val_loss: 0.5335 - val_accuracy: 0.8305\n",
      "Epoch 23/200\n",
      "390/390 [==============================] - 7508s 19s/step - loss: 0.3271 - accuracy: 0.8870 - val_loss: 0.5546 - val_accuracy: 0.8271\n",
      "Epoch 24/200\n",
      "390/390 [==============================] - 7106s 18s/step - loss: 0.3149 - accuracy: 0.8920 - val_loss: 0.4145 - val_accuracy: 0.8603\n",
      "Epoch 25/200\n",
      "390/390 [==============================] - 6558s 17s/step - loss: 0.3138 - accuracy: 0.8904 - val_loss: 0.4984 - val_accuracy: 0.8460\n",
      "Epoch 26/200\n",
      "390/390 [==============================] - 24616s 63s/step - loss: 0.2978 - accuracy: 0.8951 - val_loss: 0.6067 - val_accuracy: 0.8201\n",
      "Epoch 27/200\n",
      "390/390 [==============================] - 7157s 18s/step - loss: 0.2928 - accuracy: 0.8975 - val_loss: 0.4230 - val_accuracy: 0.8648\n",
      "Epoch 28/200\n",
      "390/390 [==============================] - 5999s 15s/step - loss: 0.2866 - accuracy: 0.8997 - val_loss: 0.7931 - val_accuracy: 0.7893\n",
      "Epoch 29/200\n",
      "390/390 [==============================] - 5498s 14s/step - loss: 0.2818 - accuracy: 0.9011 - val_loss: 0.4338 - val_accuracy: 0.8598\n",
      "Epoch 30/200\n",
      "390/390 [==============================] - 6884s 18s/step - loss: 0.2708 - accuracy: 0.9050 - val_loss: 0.6048 - val_accuracy: 0.8123\n",
      "Epoch 31/200\n",
      "390/390 [==============================] - 5492s 14s/step - loss: 0.2694 - accuracy: 0.9062 - val_loss: 0.3789 - val_accuracy: 0.8809\n",
      "Epoch 32/200\n",
      "390/390 [==============================] - 5769s 15s/step - loss: 0.2613 - accuracy: 0.9087 - val_loss: 0.4606 - val_accuracy: 0.8617\n",
      "Epoch 33/200\n",
      "390/390 [==============================] - 7892s 20s/step - loss: 0.2547 - accuracy: 0.9097 - val_loss: 0.3728 - val_accuracy: 0.8791\n",
      "Epoch 34/200\n",
      "390/390 [==============================] - 7012s 18s/step - loss: 0.2522 - accuracy: 0.9101 - val_loss: 0.4235 - val_accuracy: 0.8689\n",
      "Epoch 35/200\n",
      "390/390 [==============================] - 6421s 16s/step - loss: 0.2441 - accuracy: 0.9149 - val_loss: 0.4561 - val_accuracy: 0.8570\n",
      "Epoch 36/200\n",
      "390/390 [==============================] - 6764s 17s/step - loss: 0.2386 - accuracy: 0.9154 - val_loss: 0.5798 - val_accuracy: 0.8311\n",
      "Epoch 37/200\n",
      "390/390 [==============================] - 27972s 72s/step - loss: 0.2340 - accuracy: 0.9172 - val_loss: 0.3759 - val_accuracy: 0.8787\n",
      "Epoch 38/200\n",
      "390/390 [==============================] - 6231s 16s/step - loss: 0.2317 - accuracy: 0.9181 - val_loss: 0.3981 - val_accuracy: 0.8777\n",
      "Epoch 39/200\n",
      "390/390 [==============================] - 6241s 16s/step - loss: 0.2284 - accuracy: 0.9199 - val_loss: 0.5525 - val_accuracy: 0.8394\n",
      "Epoch 40/200\n",
      "390/390 [==============================] - 6382s 16s/step - loss: 0.2192 - accuracy: 0.9224 - val_loss: 0.3952 - val_accuracy: 0.8786\n",
      "Epoch 41/200\n",
      "390/390 [==============================] - 7370s 19s/step - loss: 0.2125 - accuracy: 0.9252 - val_loss: 0.4982 - val_accuracy: 0.8594\n",
      "Epoch 42/200\n",
      "390/390 [==============================] - 7690s 20s/step - loss: 0.2143 - accuracy: 0.9255 - val_loss: 0.3979 - val_accuracy: 0.8775\n",
      "Epoch 43/200\n",
      "390/390 [==============================] - 7508s 19s/step - loss: 0.2073 - accuracy: 0.9276 - val_loss: 0.4431 - val_accuracy: 0.8616\n",
      "Epoch 44/200\n",
      "110/390 [=======>......................] - ETA: 1:11:46 - loss: 0.1958 - accuracy: 0.9314"
     ]
    }
   ],
   "source": [
    "# Fitting the model on the batches generated by datagen.flow()\n",
    "history=model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        validation_data=(X_test,y_test), \n",
    "                        epochs=epochs, workers=4,\n",
    "                        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MXYJhTm1PY_"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7eDgbgeLqCI"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/My Drive/CNN_on_CIFR/weights-improve-130.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSRs0W0i1PZF"
   },
   "outputs": [],
   "source": [
    "labels = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck',    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcYY9wld1PZI"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns; sns.set()\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# print(\"=\"*50)\n",
    "# print(\"Confusion Matrix\") \n",
    "# print(\"=\"*50)\n",
    "# fig = plt.subplots(1,1)\n",
    "# sns.heatmap(confusion_matrix(y_test, model.predict(X_test)), cmap=\"PuBu\", annot=True, fmt=\"d\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xke4zSOB7zeZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_on_CIFR_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
